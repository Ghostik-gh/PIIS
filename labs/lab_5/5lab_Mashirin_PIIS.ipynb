{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fifteen-sailing"
   },
   "source": [
    "# Лабораторная работа №5\n",
    "### Выполнил студент группы БВТ2102 Маширин Федор Сергеевич\n",
    "## Распознавание объектов на фотографиях\n",
    "#### Цель работы: Распознавание объектов на фотографиях (Object Recognition in Photographs) CIFAR-10 (классификация небольших изображений по десяти классам: самолет,автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль и грузовик)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7436,
     "status": "ok",
     "timestamp": 1730827425245,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "AkycZhSw8XeY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1730827755229,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "Xht0D9veFgd-"
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # количество обучающих образцов, обрабатываемых одновременно за одну итерацию алгоритма градиентного спуска\n",
    "num_epochs = 200 # количество итераций обучающего алгоритма по всему обучающему множеству\n",
    "kernel_size = 3 # размер ядра в сверточных слоях\n",
    "pool_size = 2 # размер подвыборки в слоях подвыборки\n",
    "\n",
    "# количество ядер в сверточных слоях\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 64\n",
    "\n",
    "# (dropout probability) — мы будем применять dropout после каждого слоя подвыборки, а также после полносвязного слоя\n",
    "drop_prob_1 = 0.25\n",
    "drop_prob_2 = 0.5\n",
    "hidden_size = 512 # количество нейронов в полносвязном слое MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переносим изображение в одномерное пространство.  в отрезок [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2056,
     "status": "ok",
     "timestamp": 1730827994235,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "Nw56aum8F6DI"
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data() # fetch CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1730828065872,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "LyasQpfKYyzU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 3\n"
     ]
    }
   ],
   "source": [
    "num_train, height, width, depth = X_train.shape # there are 50000 training examples in CIFAR-10\n",
    "num_test = X_test.shape[0] # there are 10000 test examples in CIFAR-10\n",
    "num_classes = np.unique(Y_train).shape[0] # there are 10 image classes\n",
    "print(height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1730828069655,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "3U2MXYqxZFFW"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Normalise data to [0, 1] range\n",
    "X_test /= np.max(X_train) # Normalise data to [0, 1] range\n",
    "Y_train = to_categorical(Y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = to_categorical(Y_test, num_classes) # One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1730828130889,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "uRZ29LIZGiXN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 32, 32, 3), dtype=float32, sparse=False, name=keras_tensor_13>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(height, width, depth))\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1730828081953,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "ryf9TX7mZpJn"
   },
   "outputs": [],
   "source": [
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), padding='same')(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1) # Для регуляризации нашей модели после каждого слоя подвыборки и первого полносвязного слоя применяется слой Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1730828094386,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "yEVFFag-Zrr7"
   },
   "outputs": [],
   "source": [
    "# После первого слоя подвыборки мы удваиваем количество ядер (вместе с описанным выше принципом принесения высоты и ширины в жертву глубине).\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), padding='same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1730828098771,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "zpNuRnOFZtNS"
   },
   "outputs": [],
   "source": [
    "# Выходное изображение слоя подвыборки трансформируется в одномерный вектор (слоем Flatten) и проходит два полносвязных слоя (Dense).\n",
    "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3728465,
     "status": "ok",
     "timestamp": 1730831925333,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "AgCA76UYaTSb",
    "outputId": "76e389b7-d170-46ee-f25f-aa5fda591c45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2099 - loss: 2.0804 - val_accuracy: 0.3754 - val_loss: 1.6939\n",
      "Epoch 2/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3499 - loss: 1.7416 - val_accuracy: 0.4190 - val_loss: 1.5619\n",
      "Epoch 3/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3837 - loss: 1.6475 - val_accuracy: 0.4510 - val_loss: 1.4917\n",
      "Epoch 4/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4166 - loss: 1.5783 - val_accuracy: 0.4698 - val_loss: 1.4460\n",
      "Epoch 5/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4327 - loss: 1.5423 - val_accuracy: 0.4806 - val_loss: 1.4336\n",
      "Epoch 6/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4492 - loss: 1.4996 - val_accuracy: 0.4896 - val_loss: 1.4007\n",
      "Epoch 7/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4641 - loss: 1.4614 - val_accuracy: 0.5032 - val_loss: 1.3671\n",
      "Epoch 8/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4698 - loss: 1.4499 - val_accuracy: 0.5100 - val_loss: 1.3624\n",
      "Epoch 9/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4743 - loss: 1.4413 - val_accuracy: 0.5184 - val_loss: 1.3291\n",
      "Epoch 10/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4845 - loss: 1.4170 - val_accuracy: 0.5268 - val_loss: 1.3124\n",
      "Epoch 11/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4877 - loss: 1.4080 - val_accuracy: 0.5224 - val_loss: 1.3202\n",
      "Epoch 12/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4894 - loss: 1.3965 - val_accuracy: 0.5294 - val_loss: 1.2942\n",
      "Epoch 13/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5011 - loss: 1.3798 - val_accuracy: 0.5358 - val_loss: 1.2789\n",
      "Epoch 14/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5055 - loss: 1.3571 - val_accuracy: 0.5420 - val_loss: 1.2631\n",
      "Epoch 15/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5101 - loss: 1.3612 - val_accuracy: 0.5432 - val_loss: 1.2638\n",
      "Epoch 16/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5116 - loss: 1.3557 - val_accuracy: 0.5442 - val_loss: 1.2674\n",
      "Epoch 17/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5155 - loss: 1.3435 - val_accuracy: 0.5402 - val_loss: 1.2817\n",
      "Epoch 18/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5247 - loss: 1.3263 - val_accuracy: 0.5534 - val_loss: 1.2468\n",
      "Epoch 19/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5203 - loss: 1.3218 - val_accuracy: 0.5636 - val_loss: 1.2214\n",
      "Epoch 20/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5260 - loss: 1.3089 - val_accuracy: 0.5486 - val_loss: 1.2562\n",
      "Epoch 21/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5293 - loss: 1.3183 - val_accuracy: 0.5476 - val_loss: 1.2607\n",
      "Epoch 22/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5289 - loss: 1.3062 - val_accuracy: 0.5472 - val_loss: 1.2414\n",
      "Epoch 23/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5373 - loss: 1.2986 - val_accuracy: 0.5564 - val_loss: 1.2364\n",
      "Epoch 24/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5349 - loss: 1.2950 - val_accuracy: 0.5592 - val_loss: 1.2218\n",
      "Epoch 25/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5358 - loss: 1.2906 - val_accuracy: 0.5506 - val_loss: 1.2561\n",
      "Epoch 26/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5377 - loss: 1.2847 - val_accuracy: 0.5614 - val_loss: 1.2306\n",
      "Epoch 27/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5444 - loss: 1.2727 - val_accuracy: 0.5654 - val_loss: 1.2126\n",
      "Epoch 28/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5417 - loss: 1.2692 - val_accuracy: 0.5580 - val_loss: 1.2168\n",
      "Epoch 29/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5450 - loss: 1.2670 - val_accuracy: 0.5686 - val_loss: 1.2112\n",
      "Epoch 30/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5416 - loss: 1.2682 - val_accuracy: 0.5722 - val_loss: 1.2012\n",
      "Epoch 31/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5509 - loss: 1.2540 - val_accuracy: 0.5676 - val_loss: 1.2169\n",
      "Epoch 32/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5450 - loss: 1.2637 - val_accuracy: 0.5714 - val_loss: 1.2089\n",
      "Epoch 33/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5505 - loss: 1.2549 - val_accuracy: 0.5692 - val_loss: 1.2104\n",
      "Epoch 34/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5525 - loss: 1.2520 - val_accuracy: 0.5676 - val_loss: 1.2110\n",
      "Epoch 35/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5487 - loss: 1.2510 - val_accuracy: 0.5744 - val_loss: 1.2011\n",
      "Epoch 36/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5521 - loss: 1.2463 - val_accuracy: 0.5702 - val_loss: 1.2111\n",
      "Epoch 37/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5523 - loss: 1.2451 - val_accuracy: 0.5704 - val_loss: 1.2110\n",
      "Epoch 38/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5582 - loss: 1.2420 - val_accuracy: 0.5722 - val_loss: 1.1978\n",
      "Epoch 39/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5635 - loss: 1.2297 - val_accuracy: 0.5800 - val_loss: 1.1969\n",
      "Epoch 40/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 1.2315 - val_accuracy: 0.5724 - val_loss: 1.2027\n",
      "Epoch 41/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5607 - loss: 1.2333 - val_accuracy: 0.5770 - val_loss: 1.2023\n",
      "Epoch 42/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5554 - loss: 1.2285 - val_accuracy: 0.5778 - val_loss: 1.1976\n",
      "Epoch 43/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5634 - loss: 1.2295 - val_accuracy: 0.5608 - val_loss: 1.2102\n",
      "Epoch 44/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5635 - loss: 1.2295 - val_accuracy: 0.5758 - val_loss: 1.1876\n",
      "Epoch 45/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5599 - loss: 1.2252 - val_accuracy: 0.5790 - val_loss: 1.1944\n",
      "Epoch 46/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5613 - loss: 1.2256 - val_accuracy: 0.5776 - val_loss: 1.2135\n",
      "Epoch 47/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 1.2235 - val_accuracy: 0.5718 - val_loss: 1.1913\n",
      "Epoch 48/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5646 - loss: 1.2172 - val_accuracy: 0.5660 - val_loss: 1.2220\n",
      "Epoch 49/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5687 - loss: 1.2110 - val_accuracy: 0.5706 - val_loss: 1.1956\n",
      "Epoch 50/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5671 - loss: 1.2057 - val_accuracy: 0.5814 - val_loss: 1.1881\n",
      "Epoch 51/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5689 - loss: 1.2045 - val_accuracy: 0.5768 - val_loss: 1.1941\n",
      "Epoch 52/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5656 - loss: 1.2115 - val_accuracy: 0.5784 - val_loss: 1.1916\n",
      "Epoch 53/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5687 - loss: 1.1985 - val_accuracy: 0.5846 - val_loss: 1.1971\n",
      "Epoch 54/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 1.2041 - val_accuracy: 0.5758 - val_loss: 1.2010\n",
      "Epoch 55/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5696 - loss: 1.1974 - val_accuracy: 0.5806 - val_loss: 1.1874\n",
      "Epoch 56/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5690 - loss: 1.2037 - val_accuracy: 0.5870 - val_loss: 1.1819\n",
      "Epoch 57/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5711 - loss: 1.2039 - val_accuracy: 0.5894 - val_loss: 1.1847\n",
      "Epoch 58/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5750 - loss: 1.2004 - val_accuracy: 0.5806 - val_loss: 1.1789\n",
      "Epoch 59/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 1.1984 - val_accuracy: 0.5818 - val_loss: 1.1862\n",
      "Epoch 60/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5680 - loss: 1.2003 - val_accuracy: 0.5752 - val_loss: 1.2051\n",
      "Epoch 61/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5759 - loss: 1.1834 - val_accuracy: 0.5788 - val_loss: 1.1992\n",
      "Epoch 62/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 1.2029 - val_accuracy: 0.5832 - val_loss: 1.1772\n",
      "Epoch 63/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5816 - loss: 1.1801 - val_accuracy: 0.5850 - val_loss: 1.1808\n",
      "Epoch 64/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5782 - loss: 1.1815 - val_accuracy: 0.5838 - val_loss: 1.1728\n",
      "Epoch 65/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5739 - loss: 1.1830 - val_accuracy: 0.5880 - val_loss: 1.1754\n",
      "Epoch 66/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5748 - loss: 1.1901 - val_accuracy: 0.5852 - val_loss: 1.1791\n",
      "Epoch 67/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5817 - loss: 1.1790 - val_accuracy: 0.5750 - val_loss: 1.1940\n",
      "Epoch 68/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5772 - loss: 1.1863 - val_accuracy: 0.5786 - val_loss: 1.1984\n",
      "Epoch 69/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5797 - loss: 1.1851 - val_accuracy: 0.5792 - val_loss: 1.1748\n",
      "Epoch 70/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5782 - loss: 1.1744 - val_accuracy: 0.5842 - val_loss: 1.1904\n",
      "Epoch 71/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5809 - loss: 1.1697 - val_accuracy: 0.5768 - val_loss: 1.1922\n",
      "Epoch 72/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5780 - loss: 1.1789 - val_accuracy: 0.5824 - val_loss: 1.1833\n",
      "Epoch 73/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5816 - loss: 1.1700 - val_accuracy: 0.5770 - val_loss: 1.1793\n",
      "Epoch 74/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5777 - loss: 1.1824 - val_accuracy: 0.5842 - val_loss: 1.1765\n",
      "Epoch 75/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5744 - loss: 1.1834 - val_accuracy: 0.5874 - val_loss: 1.1742\n",
      "Epoch 76/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5800 - loss: 1.1736 - val_accuracy: 0.5810 - val_loss: 1.1810\n",
      "Epoch 77/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5811 - loss: 1.1677 - val_accuracy: 0.5930 - val_loss: 1.1766\n",
      "Epoch 78/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 1.1653 - val_accuracy: 0.5752 - val_loss: 1.2030\n",
      "Epoch 79/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 1.1695 - val_accuracy: 0.5850 - val_loss: 1.1772\n",
      "Epoch 80/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5862 - loss: 1.1628 - val_accuracy: 0.5802 - val_loss: 1.1711\n",
      "Epoch 81/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 1.1598 - val_accuracy: 0.5902 - val_loss: 1.1661\n",
      "Epoch 82/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5834 - loss: 1.1672 - val_accuracy: 0.5776 - val_loss: 1.1967\n",
      "Epoch 83/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 1.1638 - val_accuracy: 0.5882 - val_loss: 1.1838\n",
      "Epoch 84/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 1.1719 - val_accuracy: 0.5842 - val_loss: 1.1785\n",
      "Epoch 85/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5859 - loss: 1.1553 - val_accuracy: 0.5788 - val_loss: 1.1932\n",
      "Epoch 86/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 1.1603 - val_accuracy: 0.5776 - val_loss: 1.2031\n",
      "Epoch 87/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 1.1770 - val_accuracy: 0.5840 - val_loss: 1.1763\n",
      "Epoch 88/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5832 - loss: 1.1625 - val_accuracy: 0.5850 - val_loss: 1.1839\n",
      "Epoch 89/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 1.1598 - val_accuracy: 0.5916 - val_loss: 1.1691\n",
      "Epoch 90/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5848 - loss: 1.1583 - val_accuracy: 0.5786 - val_loss: 1.1892\n",
      "Epoch 91/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5871 - loss: 1.1600 - val_accuracy: 0.5834 - val_loss: 1.1867\n",
      "Epoch 92/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5872 - loss: 1.1590 - val_accuracy: 0.5786 - val_loss: 1.1857\n",
      "Epoch 93/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5919 - loss: 1.1531 - val_accuracy: 0.5834 - val_loss: 1.1936\n",
      "Epoch 94/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5850 - loss: 1.1604 - val_accuracy: 0.5938 - val_loss: 1.1794\n",
      "Epoch 95/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5890 - loss: 1.1564 - val_accuracy: 0.5834 - val_loss: 1.2018\n",
      "Epoch 96/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5906 - loss: 1.1558 - val_accuracy: 0.5818 - val_loss: 1.1711\n",
      "Epoch 97/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5850 - loss: 1.1636 - val_accuracy: 0.5828 - val_loss: 1.1791\n",
      "Epoch 98/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 1.1493 - val_accuracy: 0.5904 - val_loss: 1.1683\n",
      "Epoch 99/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5881 - loss: 1.1502 - val_accuracy: 0.5856 - val_loss: 1.1821\n",
      "Epoch 100/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5925 - loss: 1.1487 - val_accuracy: 0.5818 - val_loss: 1.1739\n",
      "Epoch 101/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5881 - loss: 1.1657 - val_accuracy: 0.5908 - val_loss: 1.1787\n",
      "Epoch 102/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5891 - loss: 1.1444 - val_accuracy: 0.5862 - val_loss: 1.1785\n",
      "Epoch 103/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5903 - loss: 1.1498 - val_accuracy: 0.5878 - val_loss: 1.1691\n",
      "Epoch 104/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 1.1403 - val_accuracy: 0.5874 - val_loss: 1.1988\n",
      "Epoch 105/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5914 - loss: 1.1449 - val_accuracy: 0.5876 - val_loss: 1.1755\n",
      "Epoch 106/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 1.1478 - val_accuracy: 0.5934 - val_loss: 1.1730\n",
      "Epoch 107/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5900 - loss: 1.1462 - val_accuracy: 0.5922 - val_loss: 1.1642\n",
      "Epoch 108/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 1.1320 - val_accuracy: 0.5912 - val_loss: 1.1737\n",
      "Epoch 109/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 1.1471 - val_accuracy: 0.5846 - val_loss: 1.1655\n",
      "Epoch 110/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5934 - loss: 1.1438 - val_accuracy: 0.5794 - val_loss: 1.1838\n",
      "Epoch 111/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 1.1457 - val_accuracy: 0.5902 - val_loss: 1.1771\n",
      "Epoch 112/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5944 - loss: 1.1423 - val_accuracy: 0.5862 - val_loss: 1.1845\n",
      "Epoch 113/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 1.1396 - val_accuracy: 0.5848 - val_loss: 1.1790\n",
      "Epoch 114/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 1.1478 - val_accuracy: 0.5902 - val_loss: 1.1683\n",
      "Epoch 115/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 1.1289 - val_accuracy: 0.5790 - val_loss: 1.1860\n",
      "Epoch 116/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5951 - loss: 1.1295 - val_accuracy: 0.5786 - val_loss: 1.1841\n",
      "Epoch 117/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5951 - loss: 1.1365 - val_accuracy: 0.5774 - val_loss: 1.1883\n",
      "Epoch 118/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5945 - loss: 1.1340 - val_accuracy: 0.5856 - val_loss: 1.1869\n",
      "Epoch 119/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5921 - loss: 1.1421 - val_accuracy: 0.5848 - val_loss: 1.1761\n",
      "Epoch 120/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5973 - loss: 1.1385 - val_accuracy: 0.5918 - val_loss: 1.1674\n",
      "Epoch 121/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5923 - loss: 1.1383 - val_accuracy: 0.5848 - val_loss: 1.1897\n",
      "Epoch 122/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5908 - loss: 1.1413 - val_accuracy: 0.5854 - val_loss: 1.1902\n",
      "Epoch 123/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 1.1329 - val_accuracy: 0.5876 - val_loss: 1.1829\n",
      "Epoch 124/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5974 - loss: 1.1302 - val_accuracy: 0.5850 - val_loss: 1.1821\n",
      "Epoch 125/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5937 - loss: 1.1465 - val_accuracy: 0.5928 - val_loss: 1.1809\n",
      "Epoch 126/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 1.1330 - val_accuracy: 0.5876 - val_loss: 1.1854\n",
      "Epoch 127/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5983 - loss: 1.1274 - val_accuracy: 0.5940 - val_loss: 1.1715\n",
      "Epoch 128/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5995 - loss: 1.1221 - val_accuracy: 0.5860 - val_loss: 1.1956\n",
      "Epoch 129/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6000 - loss: 1.1251 - val_accuracy: 0.5926 - val_loss: 1.1919\n",
      "Epoch 130/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 1.1251 - val_accuracy: 0.5952 - val_loss: 1.1750\n",
      "Epoch 131/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5968 - loss: 1.1227 - val_accuracy: 0.5854 - val_loss: 1.1941\n",
      "Epoch 132/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 1.1256 - val_accuracy: 0.5900 - val_loss: 1.1677\n",
      "Epoch 133/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6004 - loss: 1.1165 - val_accuracy: 0.5954 - val_loss: 1.1614\n",
      "Epoch 134/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5939 - loss: 1.1448 - val_accuracy: 0.5992 - val_loss: 1.1581\n",
      "Epoch 135/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 1.1257 - val_accuracy: 0.6010 - val_loss: 1.1642\n",
      "Epoch 136/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 1.1121 - val_accuracy: 0.5920 - val_loss: 1.1625\n",
      "Epoch 137/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5988 - loss: 1.1184 - val_accuracy: 0.5852 - val_loss: 1.1799\n",
      "Epoch 138/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6035 - loss: 1.1164 - val_accuracy: 0.5910 - val_loss: 1.1695\n",
      "Epoch 139/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.1151 - val_accuracy: 0.6020 - val_loss: 1.1497\n",
      "Epoch 140/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 1.1157 - val_accuracy: 0.5930 - val_loss: 1.1624\n",
      "Epoch 141/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6028 - loss: 1.1187 - val_accuracy: 0.5900 - val_loss: 1.1764\n",
      "Epoch 142/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6013 - loss: 1.1163 - val_accuracy: 0.5904 - val_loss: 1.1702\n",
      "Epoch 143/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5965 - loss: 1.1320 - val_accuracy: 0.5888 - val_loss: 1.1705\n",
      "Epoch 144/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.1189 - val_accuracy: 0.5880 - val_loss: 1.1851\n",
      "Epoch 145/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6033 - loss: 1.1237 - val_accuracy: 0.5896 - val_loss: 1.1613\n",
      "Epoch 146/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 1.1120 - val_accuracy: 0.5960 - val_loss: 1.1622\n",
      "Epoch 147/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6051 - loss: 1.1081 - val_accuracy: 0.5862 - val_loss: 1.1612\n",
      "Epoch 148/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.1201 - val_accuracy: 0.5894 - val_loss: 1.1617\n",
      "Epoch 149/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6050 - loss: 1.1105 - val_accuracy: 0.5910 - val_loss: 1.1658\n",
      "Epoch 150/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 1.1144 - val_accuracy: 0.5934 - val_loss: 1.1720\n",
      "Epoch 151/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5998 - loss: 1.1145 - val_accuracy: 0.5882 - val_loss: 1.1811\n",
      "Epoch 152/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6038 - loss: 1.1114 - val_accuracy: 0.5892 - val_loss: 1.1718\n",
      "Epoch 153/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6043 - loss: 1.1143 - val_accuracy: 0.5948 - val_loss: 1.1654\n",
      "Epoch 154/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 1.1141 - val_accuracy: 0.5982 - val_loss: 1.1684\n",
      "Epoch 155/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6037 - loss: 1.1149 - val_accuracy: 0.5972 - val_loss: 1.1563\n",
      "Epoch 156/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 1.1144 - val_accuracy: 0.5952 - val_loss: 1.1685\n",
      "Epoch 157/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6078 - loss: 1.1093 - val_accuracy: 0.5924 - val_loss: 1.1610\n",
      "Epoch 158/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6051 - loss: 1.1106 - val_accuracy: 0.6000 - val_loss: 1.1516\n",
      "Epoch 159/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6042 - loss: 1.1050 - val_accuracy: 0.6002 - val_loss: 1.1696\n",
      "Epoch 160/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5993 - loss: 1.1239 - val_accuracy: 0.5916 - val_loss: 1.1774\n",
      "Epoch 161/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 1.1109 - val_accuracy: 0.6042 - val_loss: 1.1600\n",
      "Epoch 162/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6061 - loss: 1.1152 - val_accuracy: 0.5928 - val_loss: 1.1690\n",
      "Epoch 163/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 1.1120 - val_accuracy: 0.5982 - val_loss: 1.1574\n",
      "Epoch 164/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 1.0976 - val_accuracy: 0.5958 - val_loss: 1.1628\n",
      "Epoch 165/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6032 - loss: 1.1129 - val_accuracy: 0.5862 - val_loss: 1.1723\n",
      "Epoch 166/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 1.1066 - val_accuracy: 0.5910 - val_loss: 1.1855\n",
      "Epoch 167/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6106 - loss: 1.0950 - val_accuracy: 0.5956 - val_loss: 1.1626\n",
      "Epoch 168/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6069 - loss: 1.1073 - val_accuracy: 0.5912 - val_loss: 1.1763\n",
      "Epoch 169/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6126 - loss: 1.0922 - val_accuracy: 0.6018 - val_loss: 1.1673\n",
      "Epoch 170/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 1.0990 - val_accuracy: 0.5962 - val_loss: 1.1608\n",
      "Epoch 171/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6073 - loss: 1.0991 - val_accuracy: 0.6006 - val_loss: 1.1617\n",
      "Epoch 172/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6049 - loss: 1.1033 - val_accuracy: 0.5902 - val_loss: 1.1795\n",
      "Epoch 173/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6030 - loss: 1.1124 - val_accuracy: 0.5952 - val_loss: 1.1640\n",
      "Epoch 174/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6067 - loss: 1.1020 - val_accuracy: 0.5926 - val_loss: 1.1609\n",
      "Epoch 175/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6096 - loss: 1.0985 - val_accuracy: 0.5940 - val_loss: 1.1589\n",
      "Epoch 176/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6091 - loss: 1.0964 - val_accuracy: 0.5880 - val_loss: 1.1754\n",
      "Epoch 177/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6063 - loss: 1.0926 - val_accuracy: 0.5918 - val_loss: 1.1670\n",
      "Epoch 178/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6058 - loss: 1.1037 - val_accuracy: 0.5838 - val_loss: 1.1838\n",
      "Epoch 179/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6101 - loss: 1.0950 - val_accuracy: 0.5922 - val_loss: 1.1633\n",
      "Epoch 180/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 1.0954 - val_accuracy: 0.6058 - val_loss: 1.1455\n",
      "Epoch 181/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 1.0940 - val_accuracy: 0.5936 - val_loss: 1.1603\n",
      "Epoch 182/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 1.0958 - val_accuracy: 0.5842 - val_loss: 1.1995\n",
      "Epoch 183/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6053 - loss: 1.1146 - val_accuracy: 0.5962 - val_loss: 1.1637\n",
      "Epoch 184/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 1.0949 - val_accuracy: 0.5990 - val_loss: 1.1589\n",
      "Epoch 185/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6117 - loss: 1.0989 - val_accuracy: 0.5996 - val_loss: 1.1589\n",
      "Epoch 186/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 1.0880 - val_accuracy: 0.6000 - val_loss: 1.1507\n",
      "Epoch 187/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6127 - loss: 1.0925 - val_accuracy: 0.5996 - val_loss: 1.1596\n",
      "Epoch 188/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6140 - loss: 1.0885 - val_accuracy: 0.6036 - val_loss: 1.1561\n",
      "Epoch 189/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6091 - loss: 1.0968 - val_accuracy: 0.5830 - val_loss: 1.1699\n",
      "Epoch 190/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6098 - loss: 1.1073 - val_accuracy: 0.6086 - val_loss: 1.1590\n",
      "Epoch 191/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6126 - loss: 1.0931 - val_accuracy: 0.5992 - val_loss: 1.1635\n",
      "Epoch 192/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6089 - loss: 1.0867 - val_accuracy: 0.5996 - val_loss: 1.1589\n",
      "Epoch 193/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 1.1002 - val_accuracy: 0.5962 - val_loss: 1.1502\n",
      "Epoch 194/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6112 - loss: 1.0887 - val_accuracy: 0.5884 - val_loss: 1.1889\n",
      "Epoch 195/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6092 - loss: 1.0941 - val_accuracy: 0.5920 - val_loss: 1.1730\n",
      "Epoch 196/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 1.0931 - val_accuracy: 0.5864 - val_loss: 1.1717\n",
      "Epoch 197/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6123 - loss: 1.0948 - val_accuracy: 0.5922 - val_loss: 1.1545\n",
      "Epoch 198/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6106 - loss: 1.0894 - val_accuracy: 0.5972 - val_loss: 1.1554\n",
      "Epoch 199/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 1.0981 - val_accuracy: 0.5962 - val_loss: 1.1581\n",
      "Epoch 200/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6117 - loss: 1.0920 - val_accuracy: 0.5922 - val_loss: 1.1605\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.1750 - loss: 374.4443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[377.83856201171875, 0.17790000140666962]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1)\n",
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1730833039982,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "XzX6uY3v_96E"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_user_img(path):\n",
    "    # Загружаем изображение\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Изменяем размер изображения на 32x32, как требуется моделью\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "\n",
    "    # Преобразуем пиксели в диапазон от 0 до 1\n",
    "    img = img / 255.0\n",
    "\n",
    "    img = img.reshape(1, 32, 32, 3)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    user_img0 = load_user_img('assets/0_plane.jpg')\n",
    "    user_img1 = load_user_img('assets/1_car.jpg')\n",
    "    user_img2 = load_user_img('assets/2_bird.jpg')\n",
    "    user_img3 = load_user_img('assets/3_cat.jpg')\n",
    "    user_img4 = load_user_img('assets/4_deer.jpg')\n",
    "    user_img5 = load_user_img('assets/5_dog.jpg')\n",
    "    user_img6 = load_user_img('assets/6_frog.jpg')\n",
    "    user_img7 = load_user_img('assets/7_horse.jpg')\n",
    "    user_img8 = load_user_img('assets/8_boat.jpg')\n",
    "    user_img9 = load_user_img('assets/9_truck.jpg')\n",
    "\n",
    "    pred1_0 = model.predict(user_img0)\n",
    "    pred1_1 = model.predict(user_img1)\n",
    "    pred1_2 = model.predict(user_img2)\n",
    "    pred1_3 = model.predict(user_img3)\n",
    "    pred1_4 = model.predict(user_img4)\n",
    "    pred1_5 = model.predict(user_img5)\n",
    "    pred1_6 = model.predict(user_img6)\n",
    "    pred1_7 = model.predict(user_img7)\n",
    "    pred1_8 = model.predict(user_img8)\n",
    "    pred1_9 = model.predict(user_img9)\n",
    "\n",
    "    print(f'''\n",
    "        0_plane Предсказанный объект: {np.argmax(pred1_0)}\n",
    "        1_car Предсказанный объект: {np.argmax(pred1_1)}\n",
    "        2_bird Предсказанный объект: {np.argmax(pred1_2)}\n",
    "        3_cat Предсказанный объект: {np.argmax(pred1_3)}\n",
    "        4_deer Предсказанный объект: {np.argmax(pred1_4)}\n",
    "        5_dog Предсказанный объект: {np.argmax(pred1_5)}\n",
    "        6_frog Предсказанный объект: {np.argmax(pred1_6)}\n",
    "        7_horse Предсказанный объект: {np.argmax(pred1_7)}\n",
    "        8_boat Предсказанный объект: {np.argmax(pred1_8)}\n",
    "        9_truck Предсказанный объект: {np.argmax(pred1_9)}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1730833373624,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "HdH3vyp5_-uw",
    "outputId": "f28376b8-576d-409a-e0df-44edf2ca1eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "        0_plane Предсказанный объект: 7\n",
      "        1_car Предсказанный объект: 9\n",
      "        2_bird Предсказанный объект: 4\n",
      "        3_cat Предсказанный объект: 4\n",
      "        4_deer Предсказанный объект: 1\n",
      "        5_dog Предсказанный объект: 0\n",
      "        6_frog Предсказанный объект: 6\n",
      "        7_horse Предсказанный объект: 9\n",
      "        8_boat Предсказанный объект: 9\n",
      "        9_truck Предсказанный объект: 1\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1730837859697,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "A2NdgUjYtefi"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 64\n",
    "drop_prob_1 = 0.25\n",
    "drop_prob_2 = 0.5\n",
    "hidden_size = 512\n",
    "\n",
    "\n",
    "# Conv [32] -> Conv [32] -> Pool (without dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), padding='same')(conv_2)\n",
    "# Conv [64] -> Conv [64] -> Pool (without dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(pool_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), padding='same')(conv_4)\n",
    "# Now flatten to 1D, apply Dense -> ReLU (without dropout) -> softmax\n",
    "flat = Flatten()(pool_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "out = Dense(num_classes, activation='softmax')(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403678,
     "status": "ok",
     "timestamp": 1730838281213,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "e08RGLHJtoUD",
    "outputId": "7de8700b-9ac9-4979-9168-d9c87c290852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.2479 - loss: 1.9831 - val_accuracy: 0.3836 - val_loss: 1.6497\n",
      "Epoch 2/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3974 - loss: 1.6154 - val_accuracy: 0.4316 - val_loss: 1.5358\n",
      "Epoch 3/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4451 - loss: 1.5002 - val_accuracy: 0.4520 - val_loss: 1.4736\n",
      "Epoch 4/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4753 - loss: 1.4156 - val_accuracy: 0.4908 - val_loss: 1.3843\n",
      "Epoch 5/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4917 - loss: 1.3707 - val_accuracy: 0.4988 - val_loss: 1.3525\n",
      "Epoch 6/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5154 - loss: 1.3133 - val_accuracy: 0.5256 - val_loss: 1.3104\n",
      "Epoch 7/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 1.2672 - val_accuracy: 0.5258 - val_loss: 1.3081\n",
      "Epoch 8/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5453 - loss: 1.2458 - val_accuracy: 0.5344 - val_loss: 1.2824\n",
      "Epoch 9/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5553 - loss: 1.2184 - val_accuracy: 0.5458 - val_loss: 1.2588\n",
      "Epoch 10/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5737 - loss: 1.1757 - val_accuracy: 0.5436 - val_loss: 1.2510\n",
      "Epoch 11/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5789 - loss: 1.1589 - val_accuracy: 0.5546 - val_loss: 1.2276\n",
      "Epoch 12/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 1.1327 - val_accuracy: 0.5582 - val_loss: 1.2198\n",
      "Epoch 13/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 1.1277 - val_accuracy: 0.5476 - val_loss: 1.2438\n",
      "Epoch 14/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 1.0997 - val_accuracy: 0.5546 - val_loss: 1.2236\n",
      "Epoch 15/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 1.0749 - val_accuracy: 0.5662 - val_loss: 1.2101\n",
      "Epoch 16/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6132 - loss: 1.0736 - val_accuracy: 0.5672 - val_loss: 1.2081\n",
      "Epoch 17/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6160 - loss: 1.0544 - val_accuracy: 0.5528 - val_loss: 1.2482\n",
      "Epoch 18/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6270 - loss: 1.0271 - val_accuracy: 0.5748 - val_loss: 1.1951\n",
      "Epoch 19/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6339 - loss: 1.0075 - val_accuracy: 0.5640 - val_loss: 1.2401\n",
      "Epoch 20/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6364 - loss: 1.0065 - val_accuracy: 0.5790 - val_loss: 1.1865\n",
      "Epoch 21/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6399 - loss: 0.9936 - val_accuracy: 0.5774 - val_loss: 1.2100\n",
      "Epoch 22/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6444 - loss: 0.9779 - val_accuracy: 0.5800 - val_loss: 1.1879\n",
      "Epoch 23/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6488 - loss: 0.9721 - val_accuracy: 0.5826 - val_loss: 1.1811\n",
      "Epoch 24/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6552 - loss: 0.9545 - val_accuracy: 0.5902 - val_loss: 1.1882\n",
      "Epoch 25/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6559 - loss: 0.9570 - val_accuracy: 0.5870 - val_loss: 1.1878\n",
      "Epoch 26/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6610 - loss: 0.9318 - val_accuracy: 0.5818 - val_loss: 1.2042\n",
      "Epoch 27/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6634 - loss: 0.9286 - val_accuracy: 0.5854 - val_loss: 1.2295\n",
      "Epoch 28/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6647 - loss: 0.9223 - val_accuracy: 0.5846 - val_loss: 1.2072\n",
      "Epoch 29/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6785 - loss: 0.8863 - val_accuracy: 0.5738 - val_loss: 1.2720\n",
      "Epoch 30/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6711 - loss: 0.9000 - val_accuracy: 0.5884 - val_loss: 1.2110\n",
      "Epoch 31/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6766 - loss: 0.8948 - val_accuracy: 0.5890 - val_loss: 1.1919\n",
      "Epoch 32/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6868 - loss: 0.8680 - val_accuracy: 0.5774 - val_loss: 1.2303\n",
      "Epoch 33/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6867 - loss: 0.8632 - val_accuracy: 0.5868 - val_loss: 1.2257\n",
      "Epoch 34/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6864 - loss: 0.8608 - val_accuracy: 0.5732 - val_loss: 1.2641\n",
      "Epoch 35/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6846 - loss: 0.8574 - val_accuracy: 0.5874 - val_loss: 1.2480\n",
      "Epoch 36/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6961 - loss: 0.8346 - val_accuracy: 0.5874 - val_loss: 1.2340\n",
      "Epoch 37/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6984 - loss: 0.8237 - val_accuracy: 0.5906 - val_loss: 1.2441\n",
      "Epoch 38/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6976 - loss: 0.8213 - val_accuracy: 0.5844 - val_loss: 1.2335\n",
      "Epoch 39/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7058 - loss: 0.8121 - val_accuracy: 0.5866 - val_loss: 1.2366\n",
      "Epoch 40/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7060 - loss: 0.8106 - val_accuracy: 0.5880 - val_loss: 1.2772\n",
      "Epoch 41/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7114 - loss: 0.7904 - val_accuracy: 0.5798 - val_loss: 1.2841\n",
      "Epoch 42/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7131 - loss: 0.7817 - val_accuracy: 0.5858 - val_loss: 1.2838\n",
      "Epoch 43/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7129 - loss: 0.7813 - val_accuracy: 0.5838 - val_loss: 1.2708\n",
      "Epoch 44/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7122 - loss: 0.7781 - val_accuracy: 0.5832 - val_loss: 1.2957\n",
      "Epoch 45/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7226 - loss: 0.7622 - val_accuracy: 0.5826 - val_loss: 1.3032\n",
      "Epoch 46/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7244 - loss: 0.7502 - val_accuracy: 0.5856 - val_loss: 1.2948\n",
      "Epoch 47/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7282 - loss: 0.7405 - val_accuracy: 0.5778 - val_loss: 1.3215\n",
      "Epoch 48/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7307 - loss: 0.7333 - val_accuracy: 0.5834 - val_loss: 1.3433\n",
      "Epoch 49/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7306 - loss: 0.7368 - val_accuracy: 0.5784 - val_loss: 1.3631\n",
      "Epoch 50/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7310 - loss: 0.7178 - val_accuracy: 0.5840 - val_loss: 1.3805\n",
      "Epoch 51/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7417 - loss: 0.7072 - val_accuracy: 0.5786 - val_loss: 1.3966\n",
      "Epoch 52/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.7058 - val_accuracy: 0.5878 - val_loss: 1.4158\n",
      "Epoch 53/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7416 - loss: 0.7004 - val_accuracy: 0.5784 - val_loss: 1.4039\n",
      "Epoch 54/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 0.6806 - val_accuracy: 0.5752 - val_loss: 1.4470\n",
      "Epoch 55/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.6748 - val_accuracy: 0.5738 - val_loss: 1.4435\n",
      "Epoch 56/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7576 - loss: 0.6630 - val_accuracy: 0.5708 - val_loss: 1.4369\n",
      "Epoch 57/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7586 - loss: 0.6590 - val_accuracy: 0.5670 - val_loss: 1.5143\n",
      "Epoch 58/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7627 - loss: 0.6431 - val_accuracy: 0.5712 - val_loss: 1.4735\n",
      "Epoch 59/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7615 - loss: 0.6380 - val_accuracy: 0.5720 - val_loss: 1.5302\n",
      "Epoch 60/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7638 - loss: 0.6363 - val_accuracy: 0.5742 - val_loss: 1.5306\n",
      "Epoch 61/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7672 - loss: 0.6256 - val_accuracy: 0.5656 - val_loss: 1.5693\n",
      "Epoch 62/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7747 - loss: 0.6029 - val_accuracy: 0.5764 - val_loss: 1.5627\n",
      "Epoch 63/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.5965 - val_accuracy: 0.5730 - val_loss: 1.6109\n",
      "Epoch 64/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.5957 - val_accuracy: 0.5716 - val_loss: 1.6027\n",
      "Epoch 65/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7876 - loss: 0.5783 - val_accuracy: 0.5714 - val_loss: 1.6247\n",
      "Epoch 66/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7855 - loss: 0.5805 - val_accuracy: 0.5664 - val_loss: 1.6608\n",
      "Epoch 67/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.5729 - val_accuracy: 0.5672 - val_loss: 1.6577\n",
      "Epoch 68/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.5590 - val_accuracy: 0.5542 - val_loss: 1.7390\n",
      "Epoch 69/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.5705 - val_accuracy: 0.5668 - val_loss: 1.6926\n",
      "Epoch 70/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.5537 - val_accuracy: 0.5646 - val_loss: 1.7274\n",
      "Epoch 71/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8050 - loss: 0.5267 - val_accuracy: 0.5628 - val_loss: 1.7359\n",
      "Epoch 72/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.5227 - val_accuracy: 0.5632 - val_loss: 1.8447\n",
      "Epoch 73/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.5387 - val_accuracy: 0.5634 - val_loss: 1.8168\n",
      "Epoch 74/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.5135 - val_accuracy: 0.5622 - val_loss: 1.8234\n",
      "Epoch 75/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8136 - loss: 0.5037 - val_accuracy: 0.5600 - val_loss: 1.9165\n",
      "Epoch 76/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.4983 - val_accuracy: 0.5502 - val_loss: 1.8767\n",
      "Epoch 77/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8055 - loss: 0.5155 - val_accuracy: 0.5614 - val_loss: 1.9288\n",
      "Epoch 78/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8191 - loss: 0.4873 - val_accuracy: 0.5714 - val_loss: 1.9190\n",
      "Epoch 79/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8241 - loss: 0.4736 - val_accuracy: 0.5592 - val_loss: 1.9410\n",
      "Epoch 80/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8181 - loss: 0.4819 - val_accuracy: 0.5612 - val_loss: 1.9835\n",
      "Epoch 81/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8184 - loss: 0.4815 - val_accuracy: 0.5564 - val_loss: 2.0239\n",
      "Epoch 82/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8290 - loss: 0.4544 - val_accuracy: 0.5576 - val_loss: 2.0150\n",
      "Epoch 83/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8351 - loss: 0.4483 - val_accuracy: 0.5530 - val_loss: 1.9910\n",
      "Epoch 84/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8292 - loss: 0.4563 - val_accuracy: 0.5542 - val_loss: 2.0443\n",
      "Epoch 85/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8312 - loss: 0.4476 - val_accuracy: 0.5552 - val_loss: 2.0410\n",
      "Epoch 86/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8348 - loss: 0.4440 - val_accuracy: 0.5522 - val_loss: 2.1068\n",
      "Epoch 87/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8353 - loss: 0.4394 - val_accuracy: 0.5556 - val_loss: 2.1467\n",
      "Epoch 88/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.4267 - val_accuracy: 0.5482 - val_loss: 2.1949\n",
      "Epoch 89/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8359 - loss: 0.4393 - val_accuracy: 0.5482 - val_loss: 2.2086\n",
      "Epoch 90/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8320 - loss: 0.4481 - val_accuracy: 0.5472 - val_loss: 2.1976\n",
      "Epoch 91/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8478 - loss: 0.4118 - val_accuracy: 0.5448 - val_loss: 2.2118\n",
      "Epoch 92/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8485 - loss: 0.4039 - val_accuracy: 0.5472 - val_loss: 2.2303\n",
      "Epoch 93/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8551 - loss: 0.3913 - val_accuracy: 0.5528 - val_loss: 2.3049\n",
      "Epoch 94/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8459 - loss: 0.4113 - val_accuracy: 0.5466 - val_loss: 2.2746\n",
      "Epoch 95/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8552 - loss: 0.3851 - val_accuracy: 0.5428 - val_loss: 2.3194\n",
      "Epoch 96/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.4267 - val_accuracy: 0.5510 - val_loss: 2.3326\n",
      "Epoch 97/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8505 - loss: 0.3980 - val_accuracy: 0.5472 - val_loss: 2.4372\n",
      "Epoch 98/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8470 - loss: 0.4085 - val_accuracy: 0.5430 - val_loss: 2.4291\n",
      "Epoch 99/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8548 - loss: 0.3828 - val_accuracy: 0.5442 - val_loss: 2.4462\n",
      "Epoch 100/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8624 - loss: 0.3685 - val_accuracy: 0.5386 - val_loss: 2.4948\n",
      "Epoch 101/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8619 - loss: 0.3692 - val_accuracy: 0.5490 - val_loss: 2.4805\n",
      "Epoch 102/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.3666 - val_accuracy: 0.5374 - val_loss: 2.5044\n",
      "Epoch 103/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3571 - val_accuracy: 0.5440 - val_loss: 2.5251\n",
      "Epoch 104/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8587 - loss: 0.3728 - val_accuracy: 0.5482 - val_loss: 2.5852\n",
      "Epoch 105/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3612 - val_accuracy: 0.5420 - val_loss: 2.5792\n",
      "Epoch 106/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.3759 - val_accuracy: 0.5426 - val_loss: 2.6258\n",
      "Epoch 107/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.3349 - val_accuracy: 0.5410 - val_loss: 2.8328\n",
      "Epoch 108/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8620 - loss: 0.3664 - val_accuracy: 0.5390 - val_loss: 2.6631\n",
      "Epoch 109/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8761 - loss: 0.3313 - val_accuracy: 0.5334 - val_loss: 2.7198\n",
      "Epoch 110/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8667 - loss: 0.3488 - val_accuracy: 0.5426 - val_loss: 2.7843\n",
      "Epoch 111/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.3626 - val_accuracy: 0.5402 - val_loss: 2.8012\n",
      "Epoch 112/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8761 - loss: 0.3298 - val_accuracy: 0.5442 - val_loss: 2.7771\n",
      "Epoch 113/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8710 - loss: 0.3463 - val_accuracy: 0.5394 - val_loss: 2.8704\n",
      "Epoch 114/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8762 - loss: 0.3236 - val_accuracy: 0.5450 - val_loss: 2.8562\n",
      "Epoch 115/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.3271 - val_accuracy: 0.5416 - val_loss: 2.7792\n",
      "Epoch 116/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8800 - loss: 0.3191 - val_accuracy: 0.5426 - val_loss: 2.9369\n",
      "Epoch 117/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.3211 - val_accuracy: 0.5322 - val_loss: 3.0274\n",
      "Epoch 118/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8780 - loss: 0.3290 - val_accuracy: 0.5358 - val_loss: 2.9323\n",
      "Epoch 119/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8803 - loss: 0.3174 - val_accuracy: 0.5374 - val_loss: 2.8761\n",
      "Epoch 120/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8855 - loss: 0.3039 - val_accuracy: 0.5310 - val_loss: 2.9976\n",
      "Epoch 121/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8807 - loss: 0.3226 - val_accuracy: 0.5398 - val_loss: 3.0005\n",
      "Epoch 122/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8736 - loss: 0.3338 - val_accuracy: 0.5330 - val_loss: 2.9957\n",
      "Epoch 123/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.3195 - val_accuracy: 0.5376 - val_loss: 3.1297\n",
      "Epoch 124/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.3153 - val_accuracy: 0.5398 - val_loss: 3.0704\n",
      "Epoch 125/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.3156 - val_accuracy: 0.5358 - val_loss: 3.1400\n",
      "Epoch 126/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8926 - loss: 0.2905 - val_accuracy: 0.5406 - val_loss: 3.1219\n",
      "Epoch 127/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8844 - loss: 0.3098 - val_accuracy: 0.5306 - val_loss: 3.1208\n",
      "Epoch 128/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.2873 - val_accuracy: 0.5244 - val_loss: 3.1792\n",
      "Epoch 129/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.2824 - val_accuracy: 0.5388 - val_loss: 3.2432\n",
      "Epoch 130/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.2912 - val_accuracy: 0.5404 - val_loss: 3.2998\n",
      "Epoch 131/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.2741 - val_accuracy: 0.5328 - val_loss: 3.2950\n",
      "Epoch 132/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8839 - loss: 0.3091 - val_accuracy: 0.5312 - val_loss: 3.2867\n",
      "Epoch 133/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.2650 - val_accuracy: 0.5348 - val_loss: 3.3015\n",
      "Epoch 134/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8900 - loss: 0.2937 - val_accuracy: 0.5404 - val_loss: 3.4095\n",
      "Epoch 135/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.2627 - val_accuracy: 0.5230 - val_loss: 3.4054\n",
      "Epoch 136/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8911 - loss: 0.2843 - val_accuracy: 0.5422 - val_loss: 3.4142\n",
      "Epoch 137/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.2710 - val_accuracy: 0.5384 - val_loss: 3.4172\n",
      "Epoch 138/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.2834 - val_accuracy: 0.5372 - val_loss: 3.3511\n",
      "Epoch 139/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8949 - loss: 0.2816 - val_accuracy: 0.5240 - val_loss: 3.4371\n",
      "Epoch 140/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9059 - loss: 0.2471 - val_accuracy: 0.5296 - val_loss: 3.4853\n",
      "Epoch 141/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8980 - loss: 0.2715 - val_accuracy: 0.5310 - val_loss: 3.4786\n",
      "Epoch 142/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.2886 - val_accuracy: 0.5370 - val_loss: 3.4873\n",
      "Epoch 143/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 0.2915 - val_accuracy: 0.5352 - val_loss: 3.4968\n",
      "Epoch 144/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.2439 - val_accuracy: 0.5324 - val_loss: 3.5749\n",
      "Epoch 145/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8981 - loss: 0.2766 - val_accuracy: 0.5304 - val_loss: 3.4650\n",
      "Epoch 146/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2553 - val_accuracy: 0.5402 - val_loss: 3.5879\n",
      "Epoch 147/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8997 - loss: 0.2692 - val_accuracy: 0.5350 - val_loss: 3.6036\n",
      "Epoch 148/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2725 - val_accuracy: 0.5240 - val_loss: 3.5598\n",
      "Epoch 149/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.2766 - val_accuracy: 0.5342 - val_loss: 3.6356\n",
      "Epoch 150/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9001 - loss: 0.2681 - val_accuracy: 0.5266 - val_loss: 3.7239\n",
      "Epoch 151/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9181 - loss: 0.2212 - val_accuracy: 0.5318 - val_loss: 3.7699\n",
      "Epoch 152/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8931 - loss: 0.2870 - val_accuracy: 0.5292 - val_loss: 3.6566\n",
      "Epoch 153/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9014 - loss: 0.2648 - val_accuracy: 0.5372 - val_loss: 3.7176\n",
      "Epoch 154/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.2664 - val_accuracy: 0.5276 - val_loss: 3.7863\n",
      "Epoch 155/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.2329 - val_accuracy: 0.5316 - val_loss: 3.7724\n",
      "Epoch 156/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.2706 - val_accuracy: 0.5382 - val_loss: 3.6404\n",
      "Epoch 157/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.2483 - val_accuracy: 0.5302 - val_loss: 3.7887\n",
      "Epoch 158/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.2556 - val_accuracy: 0.5294 - val_loss: 3.8027\n",
      "Epoch 159/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.2445 - val_accuracy: 0.5240 - val_loss: 3.8995\n",
      "Epoch 160/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9139 - loss: 0.2305 - val_accuracy: 0.5280 - val_loss: 3.9262\n",
      "Epoch 161/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9082 - loss: 0.2499 - val_accuracy: 0.5384 - val_loss: 3.8395\n",
      "Epoch 162/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9108 - loss: 0.2418 - val_accuracy: 0.5320 - val_loss: 3.8969\n",
      "Epoch 163/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9088 - loss: 0.2411 - val_accuracy: 0.5452 - val_loss: 3.8812\n",
      "Epoch 164/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9009 - loss: 0.2708 - val_accuracy: 0.5210 - val_loss: 3.9908\n",
      "Epoch 165/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.2391 - val_accuracy: 0.5298 - val_loss: 3.8911\n",
      "Epoch 166/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.2620 - val_accuracy: 0.5312 - val_loss: 4.0980\n",
      "Epoch 167/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2566 - val_accuracy: 0.5282 - val_loss: 3.9336\n",
      "Epoch 168/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.2384 - val_accuracy: 0.5306 - val_loss: 4.0564\n",
      "Epoch 169/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9121 - loss: 0.2388 - val_accuracy: 0.5318 - val_loss: 4.0818\n",
      "Epoch 170/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.2818 - val_accuracy: 0.5238 - val_loss: 4.0174\n",
      "Epoch 171/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.2260 - val_accuracy: 0.5294 - val_loss: 4.0129\n",
      "Epoch 172/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.2426 - val_accuracy: 0.5264 - val_loss: 4.0202\n",
      "Epoch 173/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2282 - val_accuracy: 0.5312 - val_loss: 4.1236\n",
      "Epoch 174/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9131 - loss: 0.2368 - val_accuracy: 0.5336 - val_loss: 4.0694\n",
      "Epoch 175/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9176 - loss: 0.2208 - val_accuracy: 0.5290 - val_loss: 4.0792\n",
      "Epoch 176/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2283 - val_accuracy: 0.5320 - val_loss: 4.1620\n",
      "Epoch 177/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2176 - val_accuracy: 0.5318 - val_loss: 4.0427\n",
      "Epoch 178/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9128 - loss: 0.2495 - val_accuracy: 0.5290 - val_loss: 4.1677\n",
      "Epoch 179/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9142 - loss: 0.2286 - val_accuracy: 0.5364 - val_loss: 4.2675\n",
      "Epoch 180/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2334 - val_accuracy: 0.5232 - val_loss: 4.2239\n",
      "Epoch 181/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9274 - loss: 0.1968 - val_accuracy: 0.5300 - val_loss: 4.1764\n",
      "Epoch 182/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9128 - loss: 0.2353 - val_accuracy: 0.5272 - val_loss: 4.3592\n",
      "Epoch 183/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.2433 - val_accuracy: 0.5276 - val_loss: 4.3250\n",
      "Epoch 184/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2299 - val_accuracy: 0.5296 - val_loss: 4.2393\n",
      "Epoch 185/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9143 - loss: 0.2286 - val_accuracy: 0.5306 - val_loss: 4.1832\n",
      "Epoch 186/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.2296 - val_accuracy: 0.5250 - val_loss: 4.3308\n",
      "Epoch 187/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2245 - val_accuracy: 0.5374 - val_loss: 4.3078\n",
      "Epoch 188/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.1884 - val_accuracy: 0.5262 - val_loss: 4.2901\n",
      "Epoch 189/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.2384 - val_accuracy: 0.5290 - val_loss: 4.3522\n",
      "Epoch 190/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2134 - val_accuracy: 0.5246 - val_loss: 4.4810\n",
      "Epoch 191/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9013 - loss: 0.2726 - val_accuracy: 0.5230 - val_loss: 4.2575\n",
      "Epoch 192/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.2043 - val_accuracy: 0.5248 - val_loss: 4.3456\n",
      "Epoch 193/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9183 - loss: 0.2200 - val_accuracy: 0.5286 - val_loss: 4.4517\n",
      "Epoch 194/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2167 - val_accuracy: 0.5222 - val_loss: 4.4849\n",
      "Epoch 195/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.3218 - val_accuracy: 0.5230 - val_loss: 4.4242\n",
      "Epoch 196/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9284 - loss: 0.1930 - val_accuracy: 0.5312 - val_loss: 4.4981\n",
      "Epoch 197/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2427 - val_accuracy: 0.5300 - val_loss: 4.4186\n",
      "Epoch 198/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9225 - loss: 0.2164 - val_accuracy: 0.5232 - val_loss: 4.5236\n",
      "Epoch 199/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2112 - val_accuracy: 0.5300 - val_loss: 4.5336\n",
      "Epoch 200/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9232 - loss: 0.2124 - val_accuracy: 0.5370 - val_loss: 4.4900\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2998 - loss: 1838.5487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1840.9085693359375, 0.3021000027656555]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Model(inputs=inp, outputs=out)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1)\n",
    "model2.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1730838621481,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "NlhscZb81w9e",
    "outputId": "8f8d25b9-984b-4a5d-fb48-13fef2fd51ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "        0_plane Предсказанный объект: 0\n",
      "        1_car Предсказанный объект: 9\n",
      "        2_bird Предсказанный объект: 4\n",
      "        3_cat Предсказанный объект: 4\n",
      "        4_deer Предсказанный объект: 8\n",
      "        5_dog Предсказанный объект: 0\n",
      "        6_frog Предсказанный объект: 1\n",
      "        7_horse Предсказанный объект: 1\n",
      "        8_boat Предсказанный объект: 8\n",
      "        9_truck Предсказанный объект: 1\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "test_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1376660,
     "status": "ok",
     "timestamp": 1730840625685,
     "user": {
      "displayName": "Olesya Nikiforova",
      "userId": "01031724901959931367"
     },
     "user_tz": -180
    },
    "id": "eFYCWrVVBzRd",
    "outputId": "8e9b6391-3a0d-48dc-8797-68d273f652e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.2017 - loss: 2.0886 - val_accuracy: 0.3716 - val_loss: 1.7091\n",
      "Epoch 2/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3479 - loss: 1.7452 - val_accuracy: 0.4178 - val_loss: 1.5864\n",
      "Epoch 3/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.3838 - loss: 1.6500 - val_accuracy: 0.4468 - val_loss: 1.5089\n",
      "Epoch 4/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4109 - loss: 1.5979 - val_accuracy: 0.4572 - val_loss: 1.4662\n",
      "Epoch 5/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4276 - loss: 1.5525 - val_accuracy: 0.4704 - val_loss: 1.4814\n",
      "Epoch 6/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4465 - loss: 1.5149 - val_accuracy: 0.4944 - val_loss: 1.4045\n",
      "Epoch 7/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4455 - loss: 1.4987 - val_accuracy: 0.4974 - val_loss: 1.3727\n",
      "Epoch 8/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4601 - loss: 1.4692 - val_accuracy: 0.4962 - val_loss: 1.3917\n",
      "Epoch 9/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4707 - loss: 1.4476 - val_accuracy: 0.5018 - val_loss: 1.3652\n",
      "Epoch 10/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4727 - loss: 1.4479 - val_accuracy: 0.5180 - val_loss: 1.3360\n",
      "Epoch 11/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4796 - loss: 1.4228 - val_accuracy: 0.5274 - val_loss: 1.3089\n",
      "Epoch 12/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4886 - loss: 1.4001 - val_accuracy: 0.4946 - val_loss: 1.3865\n",
      "Epoch 13/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4952 - loss: 1.4020 - val_accuracy: 0.5242 - val_loss: 1.3189\n",
      "Epoch 14/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4984 - loss: 1.3873 - val_accuracy: 0.5354 - val_loss: 1.2802\n",
      "Epoch 15/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5050 - loss: 1.3679 - val_accuracy: 0.5344 - val_loss: 1.2762\n",
      "Epoch 16/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5075 - loss: 1.3623 - val_accuracy: 0.5386 - val_loss: 1.2776\n",
      "Epoch 17/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.5098 - loss: 1.3618 - val_accuracy: 0.5448 - val_loss: 1.2651\n",
      "Epoch 18/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.5187 - loss: 1.3519 - val_accuracy: 0.5390 - val_loss: 1.2604\n",
      "Epoch 19/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5154 - loss: 1.3424 - val_accuracy: 0.5464 - val_loss: 1.2433\n",
      "Epoch 20/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5249 - loss: 1.3220 - val_accuracy: 0.5396 - val_loss: 1.2632\n",
      "Epoch 21/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5207 - loss: 1.3296 - val_accuracy: 0.5402 - val_loss: 1.2519\n",
      "Epoch 22/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.5162 - loss: 1.3245 - val_accuracy: 0.5478 - val_loss: 1.2327\n",
      "Epoch 23/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5265 - loss: 1.3145 - val_accuracy: 0.5482 - val_loss: 1.2446\n",
      "Epoch 24/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5256 - loss: 1.3191 - val_accuracy: 0.5514 - val_loss: 1.2457\n",
      "Epoch 25/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5275 - loss: 1.3039 - val_accuracy: 0.5484 - val_loss: 1.2394\n",
      "Epoch 26/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5321 - loss: 1.3025 - val_accuracy: 0.5544 - val_loss: 1.2272\n",
      "Epoch 27/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5347 - loss: 1.2919 - val_accuracy: 0.5528 - val_loss: 1.2324\n",
      "Epoch 28/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5336 - loss: 1.2853 - val_accuracy: 0.5502 - val_loss: 1.2506\n",
      "Epoch 29/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5368 - loss: 1.2843 - val_accuracy: 0.5544 - val_loss: 1.2249\n",
      "Epoch 30/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5366 - loss: 1.2896 - val_accuracy: 0.5602 - val_loss: 1.2180\n",
      "Epoch 31/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5376 - loss: 1.2853 - val_accuracy: 0.5586 - val_loss: 1.2011\n",
      "Epoch 32/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5429 - loss: 1.2715 - val_accuracy: 0.5558 - val_loss: 1.2318\n",
      "Epoch 33/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5475 - loss: 1.2674 - val_accuracy: 0.5618 - val_loss: 1.2072\n",
      "Epoch 34/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5451 - loss: 1.2638 - val_accuracy: 0.5612 - val_loss: 1.2185\n",
      "Epoch 35/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5472 - loss: 1.2623 - val_accuracy: 0.5470 - val_loss: 1.2402\n",
      "Epoch 36/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5506 - loss: 1.2609 - val_accuracy: 0.5598 - val_loss: 1.2186\n",
      "Epoch 37/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5467 - loss: 1.2637 - val_accuracy: 0.5500 - val_loss: 1.2343\n",
      "Epoch 38/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5500 - loss: 1.2560 - val_accuracy: 0.5640 - val_loss: 1.2116\n",
      "Epoch 39/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5483 - loss: 1.2520 - val_accuracy: 0.5660 - val_loss: 1.2084\n",
      "Epoch 40/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5512 - loss: 1.2428 - val_accuracy: 0.5704 - val_loss: 1.2013\n",
      "Epoch 41/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5597 - loss: 1.2412 - val_accuracy: 0.5652 - val_loss: 1.2193\n",
      "Epoch 42/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5504 - loss: 1.2544 - val_accuracy: 0.5506 - val_loss: 1.2261\n",
      "Epoch 43/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5514 - loss: 1.2517 - val_accuracy: 0.5558 - val_loss: 1.2213\n",
      "Epoch 44/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 1.2527 - val_accuracy: 0.5692 - val_loss: 1.2061\n",
      "Epoch 45/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5551 - loss: 1.2423 - val_accuracy: 0.5736 - val_loss: 1.2040\n",
      "Epoch 46/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5553 - loss: 1.2329 - val_accuracy: 0.5566 - val_loss: 1.2256\n",
      "Epoch 47/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5603 - loss: 1.2318 - val_accuracy: 0.5748 - val_loss: 1.1828\n",
      "Epoch 48/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5551 - loss: 1.2311 - val_accuracy: 0.5716 - val_loss: 1.1887\n",
      "Epoch 49/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5569 - loss: 1.2340 - val_accuracy: 0.5646 - val_loss: 1.1901\n",
      "Epoch 50/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5539 - loss: 1.2395 - val_accuracy: 0.5706 - val_loss: 1.1917\n",
      "Epoch 51/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5586 - loss: 1.2341 - val_accuracy: 0.5704 - val_loss: 1.2009\n",
      "Epoch 52/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5617 - loss: 1.2239 - val_accuracy: 0.5706 - val_loss: 1.2021\n",
      "Epoch 53/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5610 - loss: 1.2273 - val_accuracy: 0.5708 - val_loss: 1.1960\n",
      "Epoch 54/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5636 - loss: 1.2252 - val_accuracy: 0.5518 - val_loss: 1.2146\n",
      "Epoch 55/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5618 - loss: 1.2195 - val_accuracy: 0.5764 - val_loss: 1.1803\n",
      "Epoch 56/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5619 - loss: 1.2230 - val_accuracy: 0.5650 - val_loss: 1.2121\n",
      "Epoch 57/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5610 - loss: 1.2185 - val_accuracy: 0.5696 - val_loss: 1.2198\n",
      "Epoch 58/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5650 - loss: 1.2155 - val_accuracy: 0.5710 - val_loss: 1.1975\n",
      "Epoch 59/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5684 - loss: 1.2092 - val_accuracy: 0.5756 - val_loss: 1.1929\n",
      "Epoch 60/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5655 - loss: 1.2075 - val_accuracy: 0.5722 - val_loss: 1.1946\n",
      "Epoch 61/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5646 - loss: 1.2108 - val_accuracy: 0.5760 - val_loss: 1.1818\n",
      "Epoch 62/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5709 - loss: 1.2081 - val_accuracy: 0.5724 - val_loss: 1.2003\n",
      "Epoch 63/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5696 - loss: 1.2114 - val_accuracy: 0.5542 - val_loss: 1.2188\n",
      "Epoch 64/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5659 - loss: 1.2187 - val_accuracy: 0.5656 - val_loss: 1.2112\n",
      "Epoch 65/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5718 - loss: 1.2052 - val_accuracy: 0.5662 - val_loss: 1.2204\n",
      "Epoch 66/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5720 - loss: 1.1977 - val_accuracy: 0.5760 - val_loss: 1.1802\n",
      "Epoch 67/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5664 - loss: 1.2073 - val_accuracy: 0.5806 - val_loss: 1.1877\n",
      "Epoch 68/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5704 - loss: 1.1927 - val_accuracy: 0.5826 - val_loss: 1.1981\n",
      "Epoch 69/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5685 - loss: 1.1896 - val_accuracy: 0.5670 - val_loss: 1.2093\n",
      "Epoch 70/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5704 - loss: 1.2063 - val_accuracy: 0.5718 - val_loss: 1.1842\n",
      "Epoch 71/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5652 - loss: 1.2125 - val_accuracy: 0.5764 - val_loss: 1.1800\n",
      "Epoch 72/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5697 - loss: 1.1988 - val_accuracy: 0.5576 - val_loss: 1.2148\n",
      "Epoch 73/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5749 - loss: 1.1899 - val_accuracy: 0.5740 - val_loss: 1.1893\n",
      "Epoch 74/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5758 - loss: 1.1852 - val_accuracy: 0.5760 - val_loss: 1.1933\n",
      "Epoch 75/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5731 - loss: 1.1968 - val_accuracy: 0.5746 - val_loss: 1.1927\n",
      "Epoch 76/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5701 - loss: 1.1980 - val_accuracy: 0.5646 - val_loss: 1.2012\n",
      "Epoch 77/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5730 - loss: 1.1948 - val_accuracy: 0.5726 - val_loss: 1.1929\n",
      "Epoch 78/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5738 - loss: 1.1884 - val_accuracy: 0.5648 - val_loss: 1.1939\n",
      "Epoch 79/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5729 - loss: 1.1894 - val_accuracy: 0.5818 - val_loss: 1.1809\n",
      "Epoch 80/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5760 - loss: 1.1862 - val_accuracy: 0.5712 - val_loss: 1.1856\n",
      "Epoch 81/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5744 - loss: 1.1892 - val_accuracy: 0.5762 - val_loss: 1.1803\n",
      "Epoch 82/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5768 - loss: 1.1848 - val_accuracy: 0.5674 - val_loss: 1.1910\n",
      "Epoch 83/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5783 - loss: 1.1812 - val_accuracy: 0.5694 - val_loss: 1.2000\n",
      "Epoch 84/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5784 - loss: 1.1833 - val_accuracy: 0.5814 - val_loss: 1.1743\n",
      "Epoch 85/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5771 - loss: 1.1809 - val_accuracy: 0.5754 - val_loss: 1.2014\n",
      "Epoch 86/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5790 - loss: 1.1711 - val_accuracy: 0.5706 - val_loss: 1.1859\n",
      "Epoch 87/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5783 - loss: 1.1784 - val_accuracy: 0.5758 - val_loss: 1.1737\n",
      "Epoch 88/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5793 - loss: 1.1827 - val_accuracy: 0.5680 - val_loss: 1.2092\n",
      "Epoch 89/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5762 - loss: 1.1815 - val_accuracy: 0.5732 - val_loss: 1.1895\n",
      "Epoch 90/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5776 - loss: 1.1820 - val_accuracy: 0.5460 - val_loss: 1.2594\n",
      "Epoch 91/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5768 - loss: 1.1742 - val_accuracy: 0.5874 - val_loss: 1.1635\n",
      "Epoch 92/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5799 - loss: 1.1688 - val_accuracy: 0.5750 - val_loss: 1.1932\n",
      "Epoch 93/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5862 - loss: 1.1615 - val_accuracy: 0.5800 - val_loss: 1.1768\n",
      "Epoch 94/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5783 - loss: 1.1716 - val_accuracy: 0.5836 - val_loss: 1.1807\n",
      "Epoch 95/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5823 - loss: 1.1656 - val_accuracy: 0.5828 - val_loss: 1.1841\n",
      "Epoch 96/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5783 - loss: 1.1809 - val_accuracy: 0.5854 - val_loss: 1.1720\n",
      "Epoch 97/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5784 - loss: 1.1756 - val_accuracy: 0.5794 - val_loss: 1.1907\n",
      "Epoch 98/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5839 - loss: 1.1586 - val_accuracy: 0.5772 - val_loss: 1.1849\n",
      "Epoch 99/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 1.1620 - val_accuracy: 0.5840 - val_loss: 1.1802\n",
      "Epoch 100/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5829 - loss: 1.1743 - val_accuracy: 0.5828 - val_loss: 1.1761\n",
      "Epoch 1/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.1723 - loss: 2.1247 - val_accuracy: 0.3204 - val_loss: 1.7748\n",
      "Epoch 2/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.2972 - loss: 1.8275 - val_accuracy: 0.3598 - val_loss: 1.7038\n",
      "Epoch 3/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.3461 - loss: 1.7396 - val_accuracy: 0.4068 - val_loss: 1.6108\n",
      "Epoch 4/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3843 - loss: 1.6535 - val_accuracy: 0.4302 - val_loss: 1.5612\n",
      "Epoch 5/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4059 - loss: 1.6063 - val_accuracy: 0.4486 - val_loss: 1.4969\n",
      "Epoch 6/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4245 - loss: 1.5701 - val_accuracy: 0.4650 - val_loss: 1.4492\n",
      "Epoch 7/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4396 - loss: 1.5274 - val_accuracy: 0.4846 - val_loss: 1.4224\n",
      "Epoch 8/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4478 - loss: 1.5063 - val_accuracy: 0.4806 - val_loss: 1.4330\n",
      "Epoch 9/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4540 - loss: 1.4918 - val_accuracy: 0.4896 - val_loss: 1.3989\n",
      "Epoch 10/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 1.4782 - val_accuracy: 0.4938 - val_loss: 1.3852\n",
      "Epoch 11/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4689 - loss: 1.4655 - val_accuracy: 0.4990 - val_loss: 1.3917\n",
      "Epoch 12/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4635 - loss: 1.4616 - val_accuracy: 0.5056 - val_loss: 1.3612\n",
      "Epoch 13/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4696 - loss: 1.4418 - val_accuracy: 0.4972 - val_loss: 1.3830\n",
      "Epoch 14/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4763 - loss: 1.4285 - val_accuracy: 0.5108 - val_loss: 1.3589\n",
      "Epoch 15/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4848 - loss: 1.4288 - val_accuracy: 0.5012 - val_loss: 1.3691\n",
      "Epoch 16/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4917 - loss: 1.4031 - val_accuracy: 0.5038 - val_loss: 1.3583\n",
      "Epoch 17/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4897 - loss: 1.4066 - val_accuracy: 0.5202 - val_loss: 1.3368\n",
      "Epoch 18/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4895 - loss: 1.4045 - val_accuracy: 0.5058 - val_loss: 1.3548\n",
      "Epoch 19/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4989 - loss: 1.3906 - val_accuracy: 0.5146 - val_loss: 1.3377\n",
      "Epoch 20/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5031 - loss: 1.3713 - val_accuracy: 0.5188 - val_loss: 1.3342\n",
      "Epoch 21/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5010 - loss: 1.3768 - val_accuracy: 0.5120 - val_loss: 1.3434\n",
      "Epoch 22/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5018 - loss: 1.3673 - val_accuracy: 0.5238 - val_loss: 1.3152\n",
      "Epoch 23/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5035 - loss: 1.3660 - val_accuracy: 0.5156 - val_loss: 1.3216\n",
      "Epoch 24/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5071 - loss: 1.3587 - val_accuracy: 0.5122 - val_loss: 1.3587\n",
      "Epoch 25/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5097 - loss: 1.3608 - val_accuracy: 0.5234 - val_loss: 1.3195\n",
      "Epoch 26/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5092 - loss: 1.3556 - val_accuracy: 0.5286 - val_loss: 1.3180\n",
      "Epoch 27/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5097 - loss: 1.3515 - val_accuracy: 0.5292 - val_loss: 1.3426\n",
      "Epoch 28/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5119 - loss: 1.3451 - val_accuracy: 0.5236 - val_loss: 1.3260\n",
      "Epoch 29/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5102 - loss: 1.3521 - val_accuracy: 0.5226 - val_loss: 1.3300\n",
      "Epoch 30/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5147 - loss: 1.3380 - val_accuracy: 0.5328 - val_loss: 1.3235\n",
      "Epoch 31/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5139 - loss: 1.3402 - val_accuracy: 0.5238 - val_loss: 1.3260\n",
      "Epoch 32/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5185 - loss: 1.3357 - val_accuracy: 0.5276 - val_loss: 1.3063\n",
      "Epoch 33/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5135 - loss: 1.3451 - val_accuracy: 0.5256 - val_loss: 1.3110\n",
      "Epoch 34/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5191 - loss: 1.3273 - val_accuracy: 0.5304 - val_loss: 1.3085\n",
      "Epoch 35/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5243 - loss: 1.3173 - val_accuracy: 0.5306 - val_loss: 1.3107\n",
      "Epoch 36/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5250 - loss: 1.3213 - val_accuracy: 0.5322 - val_loss: 1.3184\n",
      "Epoch 37/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5217 - loss: 1.3224 - val_accuracy: 0.5360 - val_loss: 1.2998\n",
      "Epoch 38/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5280 - loss: 1.3068 - val_accuracy: 0.5274 - val_loss: 1.3148\n",
      "Epoch 39/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5260 - loss: 1.3135 - val_accuracy: 0.5176 - val_loss: 1.3396\n",
      "Epoch 40/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5245 - loss: 1.3126 - val_accuracy: 0.5246 - val_loss: 1.3144\n",
      "Epoch 41/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.5309 - loss: 1.2993 - val_accuracy: 0.5338 - val_loss: 1.3071\n",
      "Epoch 42/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.2995 - val_accuracy: 0.5324 - val_loss: 1.3302\n",
      "Epoch 43/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.3049 - val_accuracy: 0.5336 - val_loss: 1.3122\n",
      "Epoch 44/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5277 - loss: 1.3017 - val_accuracy: 0.5398 - val_loss: 1.3060\n",
      "Epoch 45/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5355 - loss: 1.2948 - val_accuracy: 0.5168 - val_loss: 1.3442\n",
      "Epoch 46/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5347 - loss: 1.2895 - val_accuracy: 0.5418 - val_loss: 1.2911\n",
      "Epoch 47/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5335 - loss: 1.2890 - val_accuracy: 0.5364 - val_loss: 1.3086\n",
      "Epoch 48/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5342 - loss: 1.2909 - val_accuracy: 0.5372 - val_loss: 1.3065\n",
      "Epoch 49/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5379 - loss: 1.2855 - val_accuracy: 0.5390 - val_loss: 1.3113\n",
      "Epoch 50/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5392 - loss: 1.2804 - val_accuracy: 0.5342 - val_loss: 1.3139\n",
      "Epoch 51/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5331 - loss: 1.2896 - val_accuracy: 0.5430 - val_loss: 1.2956\n",
      "Epoch 52/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5358 - loss: 1.2889 - val_accuracy: 0.5340 - val_loss: 1.3116\n",
      "Epoch 53/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5396 - loss: 1.2799 - val_accuracy: 0.5436 - val_loss: 1.3086\n",
      "Epoch 54/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5415 - loss: 1.2763 - val_accuracy: 0.5278 - val_loss: 1.3092\n",
      "Epoch 55/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5392 - loss: 1.2782 - val_accuracy: 0.5386 - val_loss: 1.2953\n",
      "Epoch 56/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5390 - loss: 1.2706 - val_accuracy: 0.5340 - val_loss: 1.2999\n",
      "Epoch 57/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5461 - loss: 1.2654 - val_accuracy: 0.5410 - val_loss: 1.3087\n",
      "Epoch 58/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5423 - loss: 1.2697 - val_accuracy: 0.5316 - val_loss: 1.3098\n",
      "Epoch 59/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5452 - loss: 1.2563 - val_accuracy: 0.5346 - val_loss: 1.3050\n",
      "Epoch 60/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5449 - loss: 1.2627 - val_accuracy: 0.5398 - val_loss: 1.3070\n",
      "Epoch 61/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5445 - loss: 1.2615 - val_accuracy: 0.5422 - val_loss: 1.2936\n",
      "Epoch 62/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5476 - loss: 1.2586 - val_accuracy: 0.5388 - val_loss: 1.3002\n",
      "Epoch 63/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5440 - loss: 1.2622 - val_accuracy: 0.5368 - val_loss: 1.3039\n",
      "Epoch 64/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5482 - loss: 1.2626 - val_accuracy: 0.5362 - val_loss: 1.3103\n",
      "Epoch 65/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5408 - loss: 1.2667 - val_accuracy: 0.5382 - val_loss: 1.2974\n",
      "Epoch 66/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5502 - loss: 1.2556 - val_accuracy: 0.5434 - val_loss: 1.3089\n",
      "Epoch 67/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5487 - loss: 1.2558 - val_accuracy: 0.5366 - val_loss: 1.2933\n",
      "Epoch 68/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5489 - loss: 1.2456 - val_accuracy: 0.5376 - val_loss: 1.3102\n",
      "Epoch 69/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 1.2469 - val_accuracy: 0.5396 - val_loss: 1.3021\n",
      "Epoch 70/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.5497 - loss: 1.2503 - val_accuracy: 0.5388 - val_loss: 1.3317\n",
      "Epoch 71/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5498 - loss: 1.2476 - val_accuracy: 0.5272 - val_loss: 1.3165\n",
      "Epoch 72/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5536 - loss: 1.2393 - val_accuracy: 0.5348 - val_loss: 1.3027\n",
      "Epoch 73/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 1.2424 - val_accuracy: 0.5328 - val_loss: 1.3137\n",
      "Epoch 74/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5582 - loss: 1.2309 - val_accuracy: 0.5372 - val_loss: 1.3161\n",
      "Epoch 75/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5559 - loss: 1.2298 - val_accuracy: 0.5486 - val_loss: 1.2859\n",
      "Epoch 76/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5530 - loss: 1.2400 - val_accuracy: 0.5348 - val_loss: 1.3020\n",
      "Epoch 77/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5564 - loss: 1.2374 - val_accuracy: 0.5364 - val_loss: 1.3007\n",
      "Epoch 78/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 1.2389 - val_accuracy: 0.5466 - val_loss: 1.2941\n",
      "Epoch 79/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5570 - loss: 1.2361 - val_accuracy: 0.5390 - val_loss: 1.2914\n",
      "Epoch 80/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5516 - loss: 1.2484 - val_accuracy: 0.5472 - val_loss: 1.2950\n",
      "Epoch 81/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5569 - loss: 1.2299 - val_accuracy: 0.5326 - val_loss: 1.3189\n",
      "Epoch 82/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5586 - loss: 1.2330 - val_accuracy: 0.5412 - val_loss: 1.2856\n",
      "Epoch 83/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5527 - loss: 1.2444 - val_accuracy: 0.5436 - val_loss: 1.2882\n",
      "Epoch 84/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5618 - loss: 1.2180 - val_accuracy: 0.5448 - val_loss: 1.2974\n",
      "Epoch 85/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5602 - loss: 1.2348 - val_accuracy: 0.5368 - val_loss: 1.3231\n",
      "Epoch 86/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5550 - loss: 1.2312 - val_accuracy: 0.5410 - val_loss: 1.3088\n",
      "Epoch 87/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5606 - loss: 1.2274 - val_accuracy: 0.5442 - val_loss: 1.3029\n",
      "Epoch 88/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5619 - loss: 1.2228 - val_accuracy: 0.5466 - val_loss: 1.2889\n",
      "Epoch 89/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5626 - loss: 1.2215 - val_accuracy: 0.5458 - val_loss: 1.2939\n",
      "Epoch 90/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5594 - loss: 1.2296 - val_accuracy: 0.5408 - val_loss: 1.3203\n",
      "Epoch 91/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5617 - loss: 1.2213 - val_accuracy: 0.5326 - val_loss: 1.3147\n",
      "Epoch 92/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5568 - loss: 1.2283 - val_accuracy: 0.5450 - val_loss: 1.3075\n",
      "Epoch 93/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5671 - loss: 1.2144 - val_accuracy: 0.5384 - val_loss: 1.3134\n",
      "Epoch 94/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5599 - loss: 1.2235 - val_accuracy: 0.5398 - val_loss: 1.2989\n",
      "Epoch 95/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5623 - loss: 1.2266 - val_accuracy: 0.5416 - val_loss: 1.2986\n",
      "Epoch 96/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5645 - loss: 1.2160 - val_accuracy: 0.5424 - val_loss: 1.2957\n",
      "Epoch 97/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5608 - loss: 1.2232 - val_accuracy: 0.5432 - val_loss: 1.3024\n",
      "Epoch 98/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5589 - loss: 1.2291 - val_accuracy: 0.5490 - val_loss: 1.2834\n",
      "Epoch 99/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5653 - loss: 1.2172 - val_accuracy: 0.5396 - val_loss: 1.2942\n",
      "Epoch 100/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5620 - loss: 1.2115 - val_accuracy: 0.5312 - val_loss: 1.3003\n",
      "Epoch 1/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.1554 - loss: 2.1485 - val_accuracy: 0.2522 - val_loss: 1.8943\n",
      "Epoch 2/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2601 - loss: 1.8886 - val_accuracy: 0.3194 - val_loss: 1.7952\n",
      "Epoch 3/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3136 - loss: 1.8017 - val_accuracy: 0.3858 - val_loss: 1.6514\n",
      "Epoch 4/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.3573 - loss: 1.7106 - val_accuracy: 0.4116 - val_loss: 1.5847\n",
      "Epoch 5/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3813 - loss: 1.6595 - val_accuracy: 0.4312 - val_loss: 1.5510\n",
      "Epoch 6/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4075 - loss: 1.6129 - val_accuracy: 0.4552 - val_loss: 1.4974\n",
      "Epoch 7/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4288 - loss: 1.5809 - val_accuracy: 0.4702 - val_loss: 1.4821\n",
      "Epoch 8/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4347 - loss: 1.5553 - val_accuracy: 0.4726 - val_loss: 1.4877\n",
      "Epoch 9/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4415 - loss: 1.5406 - val_accuracy: 0.4862 - val_loss: 1.4359\n",
      "Epoch 10/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4501 - loss: 1.5146 - val_accuracy: 0.4712 - val_loss: 1.4686\n",
      "Epoch 11/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4595 - loss: 1.4958 - val_accuracy: 0.4996 - val_loss: 1.4425\n",
      "Epoch 12/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4629 - loss: 1.4917 - val_accuracy: 0.4920 - val_loss: 1.4161\n",
      "Epoch 13/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4677 - loss: 1.4806 - val_accuracy: 0.4960 - val_loss: 1.4276\n",
      "Epoch 14/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4688 - loss: 1.4782 - val_accuracy: 0.5070 - val_loss: 1.4131\n",
      "Epoch 15/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4753 - loss: 1.4545 - val_accuracy: 0.5074 - val_loss: 1.4097\n",
      "Epoch 16/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4796 - loss: 1.4523 - val_accuracy: 0.5154 - val_loss: 1.3945\n",
      "Epoch 17/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4814 - loss: 1.4457 - val_accuracy: 0.4996 - val_loss: 1.4197\n",
      "Epoch 18/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4856 - loss: 1.4284 - val_accuracy: 0.5128 - val_loss: 1.3832\n",
      "Epoch 19/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4920 - loss: 1.4173 - val_accuracy: 0.4938 - val_loss: 1.4093\n",
      "Epoch 20/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4919 - loss: 1.4197 - val_accuracy: 0.5204 - val_loss: 1.3527\n",
      "Epoch 21/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4956 - loss: 1.4117 - val_accuracy: 0.5104 - val_loss: 1.3998\n",
      "Epoch 22/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4975 - loss: 1.4080 - val_accuracy: 0.5178 - val_loss: 1.3798\n",
      "Epoch 23/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4988 - loss: 1.3974 - val_accuracy: 0.4962 - val_loss: 1.3952\n",
      "Epoch 24/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4970 - loss: 1.4040 - val_accuracy: 0.4936 - val_loss: 1.4658\n",
      "Epoch 25/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5008 - loss: 1.3972 - val_accuracy: 0.5078 - val_loss: 1.3984\n",
      "Epoch 26/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5028 - loss: 1.3907 - val_accuracy: 0.5178 - val_loss: 1.3840\n",
      "Epoch 27/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5025 - loss: 1.3867 - val_accuracy: 0.5152 - val_loss: 1.3704\n",
      "Epoch 28/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5080 - loss: 1.3759 - val_accuracy: 0.5074 - val_loss: 1.3754\n",
      "Epoch 29/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5088 - loss: 1.3656 - val_accuracy: 0.5116 - val_loss: 1.3707\n",
      "Epoch 30/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5131 - loss: 1.3621 - val_accuracy: 0.5144 - val_loss: 1.3825\n",
      "Epoch 31/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5105 - loss: 1.3677 - val_accuracy: 0.5088 - val_loss: 1.4077\n",
      "Epoch 32/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5133 - loss: 1.3589 - val_accuracy: 0.5248 - val_loss: 1.3589\n",
      "Epoch 33/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5203 - loss: 1.3523 - val_accuracy: 0.5188 - val_loss: 1.3903\n",
      "Epoch 34/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5177 - loss: 1.3485 - val_accuracy: 0.5164 - val_loss: 1.3752\n",
      "Epoch 35/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5178 - loss: 1.3475 - val_accuracy: 0.5266 - val_loss: 1.3545\n",
      "Epoch 36/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5174 - loss: 1.3542 - val_accuracy: 0.5226 - val_loss: 1.3653\n",
      "Epoch 37/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5217 - loss: 1.3456 - val_accuracy: 0.5276 - val_loss: 1.3880\n",
      "Epoch 38/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5248 - loss: 1.3426 - val_accuracy: 0.5210 - val_loss: 1.3602\n",
      "Epoch 39/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5219 - loss: 1.3455 - val_accuracy: 0.5170 - val_loss: 1.3789\n",
      "Epoch 40/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5256 - loss: 1.3358 - val_accuracy: 0.5214 - val_loss: 1.3766\n",
      "Epoch 41/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5260 - loss: 1.3318 - val_accuracy: 0.5130 - val_loss: 1.3830\n",
      "Epoch 42/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5287 - loss: 1.3276 - val_accuracy: 0.5326 - val_loss: 1.3609\n",
      "Epoch 43/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 1.3225 - val_accuracy: 0.5116 - val_loss: 1.4001\n",
      "Epoch 44/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5265 - loss: 1.3316 - val_accuracy: 0.5118 - val_loss: 1.4156\n",
      "Epoch 45/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5310 - loss: 1.3232 - val_accuracy: 0.5296 - val_loss: 1.3661\n",
      "Epoch 46/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5279 - loss: 1.3124 - val_accuracy: 0.5332 - val_loss: 1.3655\n",
      "Epoch 47/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5311 - loss: 1.3118 - val_accuracy: 0.5118 - val_loss: 1.3711\n",
      "Epoch 48/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5311 - loss: 1.3167 - val_accuracy: 0.5214 - val_loss: 1.3524\n",
      "Epoch 49/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5322 - loss: 1.3161 - val_accuracy: 0.5242 - val_loss: 1.3708\n",
      "Epoch 50/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5344 - loss: 1.3221 - val_accuracy: 0.5300 - val_loss: 1.3632\n",
      "Epoch 51/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5367 - loss: 1.3090 - val_accuracy: 0.5312 - val_loss: 1.3489\n",
      "Epoch 52/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5361 - loss: 1.3058 - val_accuracy: 0.5266 - val_loss: 1.3618\n",
      "Epoch 53/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5336 - loss: 1.3135 - val_accuracy: 0.5286 - val_loss: 1.3705\n",
      "Epoch 54/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5318 - loss: 1.3105 - val_accuracy: 0.5354 - val_loss: 1.3465\n",
      "Epoch 55/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5355 - loss: 1.3044 - val_accuracy: 0.5314 - val_loss: 1.3656\n",
      "Epoch 56/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5437 - loss: 1.2940 - val_accuracy: 0.5338 - val_loss: 1.3539\n",
      "Epoch 57/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5384 - loss: 1.2936 - val_accuracy: 0.5324 - val_loss: 1.3669\n",
      "Epoch 58/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5366 - loss: 1.3034 - val_accuracy: 0.5170 - val_loss: 1.4162\n",
      "Epoch 59/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5388 - loss: 1.2975 - val_accuracy: 0.5250 - val_loss: 1.3529\n",
      "Epoch 60/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5432 - loss: 1.3018 - val_accuracy: 0.5280 - val_loss: 1.3602\n",
      "Epoch 61/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5400 - loss: 1.2909 - val_accuracy: 0.5332 - val_loss: 1.3728\n",
      "Epoch 62/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5468 - loss: 1.2794 - val_accuracy: 0.5184 - val_loss: 1.3749\n",
      "Epoch 63/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5382 - loss: 1.3074 - val_accuracy: 0.5232 - val_loss: 1.3797\n",
      "Epoch 64/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5443 - loss: 1.2828 - val_accuracy: 0.5198 - val_loss: 1.3889\n",
      "Epoch 65/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5488 - loss: 1.2769 - val_accuracy: 0.5170 - val_loss: 1.4203\n",
      "Epoch 66/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5436 - loss: 1.2833 - val_accuracy: 0.5326 - val_loss: 1.3603\n",
      "Epoch 67/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5503 - loss: 1.2724 - val_accuracy: 0.5200 - val_loss: 1.3627\n",
      "Epoch 68/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5455 - loss: 1.2877 - val_accuracy: 0.5288 - val_loss: 1.3940\n",
      "Epoch 69/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5500 - loss: 1.2810 - val_accuracy: 0.5406 - val_loss: 1.3486\n",
      "Epoch 70/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5479 - loss: 1.2802 - val_accuracy: 0.5380 - val_loss: 1.3596\n",
      "Epoch 71/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5428 - loss: 1.2849 - val_accuracy: 0.5246 - val_loss: 1.3831\n",
      "Epoch 72/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5522 - loss: 1.2677 - val_accuracy: 0.5422 - val_loss: 1.3389\n",
      "Epoch 73/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5502 - loss: 1.2889 - val_accuracy: 0.5258 - val_loss: 1.3793\n",
      "Epoch 74/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5451 - loss: 1.2771 - val_accuracy: 0.5402 - val_loss: 1.3569\n",
      "Epoch 75/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5441 - loss: 1.2772 - val_accuracy: 0.5234 - val_loss: 1.3963\n",
      "Epoch 76/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5522 - loss: 1.2707 - val_accuracy: 0.5224 - val_loss: 1.3816\n",
      "Epoch 77/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5534 - loss: 1.2632 - val_accuracy: 0.5478 - val_loss: 1.3406\n",
      "Epoch 78/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5490 - loss: 1.2720 - val_accuracy: 0.5264 - val_loss: 1.3877\n",
      "Epoch 79/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5517 - loss: 1.2696 - val_accuracy: 0.5206 - val_loss: 1.3956\n",
      "Epoch 80/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5523 - loss: 1.2708 - val_accuracy: 0.5402 - val_loss: 1.3468\n",
      "Epoch 81/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5519 - loss: 1.2669 - val_accuracy: 0.5228 - val_loss: 1.3578\n",
      "Epoch 82/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5537 - loss: 1.2622 - val_accuracy: 0.5404 - val_loss: 1.3467\n",
      "Epoch 83/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 1.2682 - val_accuracy: 0.5386 - val_loss: 1.3316\n",
      "Epoch 84/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5517 - loss: 1.2657 - val_accuracy: 0.5242 - val_loss: 1.3767\n",
      "Epoch 85/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5578 - loss: 1.2517 - val_accuracy: 0.5306 - val_loss: 1.3546\n",
      "Epoch 86/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 1.2616 - val_accuracy: 0.5308 - val_loss: 1.3648\n",
      "Epoch 87/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 1.2604 - val_accuracy: 0.5376 - val_loss: 1.3687\n",
      "Epoch 88/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5563 - loss: 1.2571 - val_accuracy: 0.5314 - val_loss: 1.3717\n",
      "Epoch 89/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5590 - loss: 1.2580 - val_accuracy: 0.5160 - val_loss: 1.4070\n",
      "Epoch 90/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5538 - loss: 1.2558 - val_accuracy: 0.5288 - val_loss: 1.3667\n",
      "Epoch 91/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 1.2510 - val_accuracy: 0.5250 - val_loss: 1.3819\n",
      "Epoch 92/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5565 - loss: 1.2612 - val_accuracy: 0.5330 - val_loss: 1.3680\n",
      "Epoch 93/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5542 - loss: 1.2610 - val_accuracy: 0.5300 - val_loss: 1.3773\n",
      "Epoch 94/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5583 - loss: 1.2591 - val_accuracy: 0.5262 - val_loss: 1.3850\n",
      "Epoch 95/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5614 - loss: 1.2582 - val_accuracy: 0.5162 - val_loss: 1.4184\n",
      "Epoch 96/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5612 - loss: 1.2566 - val_accuracy: 0.5284 - val_loss: 1.3634\n",
      "Epoch 97/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5591 - loss: 1.2556 - val_accuracy: 0.5360 - val_loss: 1.3557\n",
      "Epoch 98/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 1.2460 - val_accuracy: 0.5342 - val_loss: 1.3880\n",
      "Epoch 99/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5560 - loss: 1.2583 - val_accuracy: 0.5286 - val_loss: 1.3549\n",
      "Epoch 100/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5586 - loss: 1.2522 - val_accuracy: 0.5448 - val_loss: 1.3500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "kernel_sizes = [3, 5, 7]\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 64\n",
    "drop_prob_1 = 0.25\n",
    "drop_prob_2 = 0.5\n",
    "hidden_size = 512\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "models2=[] \n",
    "for kernel_size in kernel_sizes:\n",
    "\n",
    "  # Conv [32] -> Conv [32] -> Pool\n",
    "  conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(inp)\n",
    "  conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "  pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), padding='same')(conv_2)\n",
    "  drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "  # Conv [64] -> Conv [64] -> Pool\n",
    "  conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "  conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "  pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), padding='same')(conv_4)\n",
    "  drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "\n",
    "  flat = Flatten()(drop_2)\n",
    "  hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "  drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "  out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "  model3 = Model(inputs=inp, outputs=out)\n",
    "  model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  model3.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1)\n",
    "  \n",
    "  models2.append(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "модель №0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "        0_plane Предсказанный объект: 0\n",
      "        1_car Предсказанный объект: 9\n",
      "        2_bird Предсказанный объект: 0\n",
      "        3_cat Предсказанный объект: 9\n",
      "        4_deer Предсказанный объект: 8\n",
      "        5_dog Предсказанный объект: 0\n",
      "        6_frog Предсказанный объект: 1\n",
      "        7_horse Предсказанный объект: 7\n",
      "        8_boat Предсказанный объект: 8\n",
      "        9_truck Предсказанный объект: 1\n",
      "        \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2014 - loss: 288.2795\n",
      "Test loss for kernel size 3: 287.19525146484375\n",
      "Test accuracy for kernel size 3: 0.20200000703334808\n",
      "модель №1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "        0_plane Предсказанный объект: 0\n",
      "        1_car Предсказанный объект: 9\n",
      "        2_bird Предсказанный объект: 4\n",
      "        3_cat Предсказанный объект: 6\n",
      "        4_deer Предсказанный объект: 0\n",
      "        5_dog Предсказанный объект: 2\n",
      "        6_frog Предсказанный объект: 1\n",
      "        7_horse Предсказанный объект: 2\n",
      "        8_boat Предсказанный объект: 1\n",
      "        9_truck Предсказанный объект: 1\n",
      "        \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3077 - loss: 156.0605\n",
      "Test loss for kernel size 5: 156.33995056152344\n",
      "Test accuracy for kernel size 5: 0.3086000084877014\n",
      "модель №2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "        0_plane Предсказанный объект: 0\n",
      "        1_car Предсказанный объект: 1\n",
      "        2_bird Предсказанный объект: 4\n",
      "        3_cat Предсказанный объект: 3\n",
      "        4_deer Предсказанный объект: 8\n",
      "        5_dog Предсказанный объект: 0\n",
      "        6_frog Предсказанный объект: 1\n",
      "        7_horse Предсказанный объект: 7\n",
      "        8_boat Предсказанный объект: 0\n",
      "        9_truck Предсказанный объект: 0\n",
      "        \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3348 - loss: 113.2147\n",
      "Test loss for kernel size 7: 114.54350280761719\n",
      "Test accuracy for kernel size 7: 0.3361999988555908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, model in enumerate(models2):\n",
    "    kernel_size = x * 2 + 3\n",
    "    print(f\"модель №{x}\")\n",
    "    test_model(model)\n",
    "    score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print(f\"Test loss for kernel size {kernel_size}: {score[0]}\")\n",
    "    print(f\"Test accuracy for kernel size {kernel_size}: {score[1]}\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1KrVXbsvXN7_fDtH3Qlgxp0HTFt-e0qPD",
     "timestamp": 1725986794173
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
